{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T14:40:31.872392Z",
     "iopub.status.busy": "2025-06-25T14:40:31.871638Z",
     "iopub.status.idle": "2025-06-25T14:40:35.056509Z",
     "shell.execute_reply": "2025-06-25T14:40:35.055646Z",
     "shell.execute_reply.started": "2025-06-25T14:40:31.872351Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install evaluate jiwer sacrebleu rich -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T14:40:35.058648Z",
     "iopub.status.busy": "2025-06-25T14:40:35.058418Z",
     "iopub.status.idle": "2025-06-25T14:40:35.356978Z",
     "shell.execute_reply": "2025-06-25T14:40:35.356412Z",
     "shell.execute_reply.started": "2025-06-25T14:40:35.058627Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "import evaluate \n",
    "import jiwer\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "from rich.console import Console\n",
    "from rich.table import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T14:40:35.357824Z",
     "iopub.status.busy": "2025-06-25T14:40:35.357636Z",
     "iopub.status.idle": "2025-06-25T14:40:35.362220Z",
     "shell.execute_reply": "2025-06-25T14:40:35.361408Z",
     "shell.execute_reply.started": "2025-06-25T14:40:35.357809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TrainingConfig:\n",
    "\n",
    "    MODEL_NAME = \"t5-base\" \n",
    "    DATASET_PATH = \"/kaggle/input/ocr-post-correction/combined.csv\" \n",
    "    INPUT_COLUMN = \"input_text\"  \n",
    "    TARGET_COLUMN = \"output_text\" \n",
    "    PREFIX = \"correct OCR error: \" \n",
    "    MODEL_OUTPUT_DIR = \"./ocr_correction_model\" \n",
    "    \n",
    "    # Training hyperparameters\n",
    "    LEARNING_RATE = 2e-5\n",
    "    NUM_EPOCHS = 10 \n",
    "    BATCH_SIZE = 16 \n",
    "    WEIGHT_DECAY = 0.01\n",
    "    LOGGING_STEPS = 100\n",
    "    SAVE_STEPS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T14:40:35.363439Z",
     "iopub.status.busy": "2025-06-25T14:40:35.363168Z",
     "iopub.status.idle": "2025-06-25T16:32:46.000078Z",
     "shell.execute_reply": "2025-06-25T16:32:45.999192Z",
     "shell.execute_reply.started": "2025-06-25T14:40:35.363404Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db123de566bf44909671250dc1dfa4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa92e934195e49c78af8fa56b7b7e3f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9eb7adee97f482987fbc06d10580b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c44873e74e246c3b9ac2a1404c41d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15820 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbc6a95abe54c5491052ae44328dfb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1758 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7cc0c9e37e457193d740b9d1da2e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfa9803a8644778bfd4ab82c5460ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/3218032789.py:70: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4950' max='4950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4950/4950 1:51:56, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.400900</td>\n",
       "      <td>0.310984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.330900</td>\n",
       "      <td>0.261883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.293900</td>\n",
       "      <td>0.235851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.272600</td>\n",
       "      <td>0.219290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.256400</td>\n",
       "      <td>0.206588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.197185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.237200</td>\n",
       "      <td>0.191480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.230700</td>\n",
       "      <td>0.186337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.227900</td>\n",
       "      <td>0.184093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.227500</td>\n",
       "      <td>0.183071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the entire training and evaluation pipeline.\n",
    "    \"\"\"\n",
    "    config = TrainingConfig()\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(config.DATASET_PATH)\n",
    "        \n",
    "        if config.INPUT_COLUMN not in df.columns or config.TARGET_COLUMN not in df.columns:\n",
    "            print(f\"Warning: Columns '{config.INPUT_COLUMN}' and '{config.TARGET_COLUMN}' not found.\")\n",
    "            df.columns = [config.INPUT_COLUMN, config.TARGET_COLUMN]\n",
    "            print(f\"Assigned column names: {df.columns.tolist()}\")\n",
    "\n",
    "        dataset = Dataset.from_pandas(df)\n",
    "        dataset = dataset.train_test_split(test_size=0.1)\n",
    "        \n",
    "        # print(f\"Dataset loaded. Training examples: {len(dataset['train'])}, Validation examples: {len(dataset['test'])}\")\n",
    "        # print(\"Sample data:\", dataset['train'][0])\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{config.DATASET_PATH}' was not found.\")\n",
    "        return\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        # adding prefix on each tokens for our custom OCR task\n",
    "        inputs = [config.PREFIX + doc for doc in examples[config.INPUT_COLUMN]]\n",
    "        model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\")\n",
    "        \n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = tokenizer(examples[config.TARGET_COLUMN], max_length=128, truncation=True, padding=\"max_length\")\n",
    "        \n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        return model_inputs\n",
    "\n",
    "    tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "    \n",
    "    # Fine-tuning the T5-Base Seq2Seq Model\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(config.MODEL_NAME)\n",
    "    \n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=config.MODEL_OUTPUT_DIR,\n",
    "        num_train_epochs=config.NUM_EPOCHS,\n",
    "        per_device_train_batch_size=config.BATCH_SIZE,\n",
    "        per_device_eval_batch_size=config.BATCH_SIZE,\n",
    "        learning_rate=config.LEARNING_RATE,\n",
    "        weight_decay=config.WEIGHT_DECAY,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps=config.LOGGING_STEPS,\n",
    "        predict_with_generate=True,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        push_to_hub=False,\n",
    "        save_total_limit=2,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    \n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer=tokenizer, \n",
    "        model=model\n",
    "    )\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    trainer.save_model(config.MODEL_OUTPUT_DIR)\n",
    "    tokenizer.save_pretrained(config.MODEL_OUTPUT_DIR)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T16:32:46.003513Z",
     "iopub.status.busy": "2025-06-25T16:32:46.003259Z",
     "iopub.status.idle": "2025-06-25T16:32:46.007699Z",
     "shell.execute_reply": "2025-06-25T16:32:46.006908Z",
     "shell.execute_reply.started": "2025-06-25T16:32:46.003489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !zip -r ocr_correction_model.zip /kaggle/working/ocr_correction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T16:32:46.008877Z",
     "iopub.status.busy": "2025-06-25T16:32:46.008549Z",
     "iopub.status.idle": "2025-06-25T16:32:50.604704Z",
     "shell.execute_reply": "2025-06-25T16:32:50.603908Z",
     "shell.execute_reply.started": "2025-06-25T16:32:46.008832Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate jiwer sacrebleu rich -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T16:55:03.433548Z",
     "iopub.status.busy": "2025-06-25T16:55:03.433279Z",
     "iopub.status.idle": "2025-06-25T17:00:18.279167Z",
     "shell.execute_reply": "2025-06-25T17:00:18.278614Z",
     "shell.execute_reply.started": "2025-06-25T16:55:03.433530Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:55:03] </span>Model loaded successfully.                                                              <a href=\"file:///tmp/ipykernel_35/1029302692.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1029302692.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_35/1029302692.py#19\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">19</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:55:03]\u001b[0m\u001b[2;36m \u001b[0mModel loaded successfully.                                                              \u001b]8;id=681453;file:///tmp/ipykernel_35/1029302692.py\u001b\\\u001b[2m1029302692.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///tmp/ipykernel_35/1029302692.py#19\u001b\\\u001b[2m19\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">       Model Evaluation Report        </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Metric                    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">  Score </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Character Error Rate      </span>│ 0.0296 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> (CER)                     </span>│        │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Word Error Rate (WER)     </span>│ 0.1449 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> BLEU Score                </span>│ 81.19) │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Exact Match (EM %)        </span>│  1.71% │\n",
       "└───────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m       Model Evaluation Report        \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35mMetric                   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m Score\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2mCharacter Error Rate     \u001b[0m\u001b[2m \u001b[0m│ 0.0296 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m(CER)                    \u001b[0m\u001b[2m \u001b[0m│        │\n",
       "│\u001b[2m \u001b[0m\u001b[2mWord Error Rate (WER)    \u001b[0m\u001b[2m \u001b[0m│ 0.1449 │\n",
       "│\u001b[2m \u001b[0m\u001b[2mBLEU Score               \u001b[0m\u001b[2m \u001b[0m│ 81.19) │\n",
       "│\u001b[2m \u001b[0m\u001b[2mExact Match (EM %)       \u001b[0m\u001b[2m \u001b[0m│  1.71% │\n",
       "└───────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">\\ Random Sample Predictions ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m\\ Random Sample Predictions ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                     Sample 1                                                      </span>\n",
       " <span style=\"font-weight: bold\">Input</span>            : 'ID: 5Z377S73, Name: Lokendra8ir Saam, DOB: Date: %2004/04/29, Gender: Mal3, District: Rolqa,  \n",
       "                  Municipality: Karnalbazar, Father's name: Sugam  Kumar Chavhan, Mother's name: Ahima L@ta        \n",
       "                  Paudel'                                                                                          \n",
       " <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Ground Truth</span>     : 'ID: 52377573, Name: Lokendra Bir Saam, DOB: 2004-04-29, Gender: Male, District: Rolpa,        \n",
       "                  Municipality: Kamalbazar, Father's Name: Sugam Kumar Chauhan, Mother's Name: Anima Lata Paudel'  \n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Model Output</span>     : 'ID: 52377573, Name: Lokendrashar Saam, DOB: 2004-04-29, Gender: Male, District: Rolpa,        \n",
       "                  Municipality: Karnalbazar, Father's Name: Sugam Kumar Chauhan, Mother's Name: Ahima Lata Paudel' \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                     Sample 1                                                      \u001b[0m\n",
       " \u001b[1mInput\u001b[0m            : 'ID: 5Z377S73, Name: Lokendra8ir Saam, DOB: Date: %2004/04/29, Gender: Mal3, District: Rolqa,  \n",
       "                  Municipality: Karnalbazar, Father's name: Sugam  Kumar Chavhan, Mother's name: Ahima L@ta        \n",
       "                  Paudel'                                                                                          \n",
       " \u001b[1;32mGround Truth\u001b[0m     : 'ID: 52377573, Name: Lokendra Bir Saam, DOB: 2004-04-29, Gender: Male, District: Rolpa,        \n",
       "                  Municipality: Kamalbazar, Father's Name: Sugam Kumar Chauhan, Mother's Name: Anima Lata Paudel'  \n",
       " \u001b[1;36mModel Output\u001b[0m     : 'ID: 52377573, Name: Lokendrashar Saam, DOB: 2004-04-29, Gender: Male, District: Rolpa,        \n",
       "                  Municipality: Karnalbazar, Father's Name: Sugam Kumar Chauhan, Mother's Name: Ahima Lata Paudel' \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                     Sample 2                                                      </span>\n",
       " <span style=\"font-weight: bold\">Input</span>            : 'ID: 608644424, Name: RobiRajbansh#i, DOB: Date: 200/11/_11, Gender: Mal~e, District: Huml@,   \n",
       "                  Municipality: K@urkot, Father's name: Nirol NarsinghChamlagain, Mother's name: Aleera            \n",
       "                  Priyanza1a~ Halc laliya'                                                                         \n",
       " <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Ground Truth</span>     : 'ID: 60864424, Name: Robi Rajbanshi, DOB: 2004-11-11, Gender: Male, District: Humla,           \n",
       "                  Municipality: Kapurkot, Father's Name: Nirol Narsingh Chamlagain, Mother's Name: Aleena          \n",
       "                  Priyanzala Haldaliya'                                                                            \n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Model Output</span>     : 'ID: 60864424, Name: Robi Rajbanshi, DOB: 2000-11-11, Gender: Male, District: Humla,           \n",
       "                  Municipality: Kurkot, Father's Name: Nirol Narsingh Chamlagain, Mother's Name: Aleera Priyanzala \n",
       "                  Haldaliya'                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                     Sample 2                                                      \u001b[0m\n",
       " \u001b[1mInput\u001b[0m            : 'ID: 608644424, Name: RobiRajbansh#i, DOB: Date: 200/11/_11, Gender: Mal~e, District: Huml@,   \n",
       "                  Municipality: K@urkot, Father's name: Nirol NarsinghChamlagain, Mother's name: Aleera            \n",
       "                  Priyanza1a~ Halc laliya'                                                                         \n",
       " \u001b[1;32mGround Truth\u001b[0m     : 'ID: 60864424, Name: Robi Rajbanshi, DOB: 2004-11-11, Gender: Male, District: Humla,           \n",
       "                  Municipality: Kapurkot, Father's Name: Nirol Narsingh Chamlagain, Mother's Name: Aleena          \n",
       "                  Priyanzala Haldaliya'                                                                            \n",
       " \u001b[1;36mModel Output\u001b[0m     : 'ID: 60864424, Name: Robi Rajbanshi, DOB: 2000-11-11, Gender: Male, District: Humla,           \n",
       "                  Municipality: Kurkot, Father's Name: Nirol Narsingh Chamlagain, Mother's Name: Aleera Priyanzala \n",
       "                  Haldaliya'                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                     Sample 3                                                      </span>\n",
       " <span style=\"font-weight: bold\">Input</span>            : 'ID: 69A19658, Name: Ruchika Prabha Du1al, DOB: DOB: 18-02-1987, Gender: Fen nale, District:   \n",
       "                  Su,khet, Municipality: Sabh@pokh%ari, Father's name: NitesDom, Mother's name: hijaLha@mu Rawal'  \n",
       " <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Ground Truth</span>     : 'ID: 69419658, Name: Ruchika Prabha Dulal, DOB: 1987-02-18, Gender: Female, District: Surkhet, \n",
       "                  Municipality: Sabhapokhari, Father's Name: Nites Dom, Mother's Name: Shija Lhamu Rawal'          \n",
       " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Model Output</span>     : 'ID: 69419658, Name: Ruchika Prabha Dulaal, DOB: 1987-02-18, Gender: Female, District:         \n",
       "                  Sindhuli, Municipality: Sabhapokhari, Father's Name: Nites Dom, Mother's Name: Hija Lhamu Rawal' \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                     Sample 3                                                      \u001b[0m\n",
       " \u001b[1mInput\u001b[0m            : 'ID: 69A19658, Name: Ruchika Prabha Du1al, DOB: DOB: 18-02-1987, Gender: Fen nale, District:   \n",
       "                  Su,khet, Municipality: Sabh@pokh%ari, Father's name: NitesDom, Mother's name: hijaLha@mu Rawal'  \n",
       " \u001b[1;32mGround Truth\u001b[0m     : 'ID: 69419658, Name: Ruchika Prabha Dulal, DOB: 1987-02-18, Gender: Female, District: Surkhet, \n",
       "                  Municipality: Sabhapokhari, Father's Name: Nites Dom, Mother's Name: Shija Lhamu Rawal'          \n",
       " \u001b[1;36mModel Output\u001b[0m     : 'ID: 69419658, Name: Ruchika Prabha Dulaal, DOB: 1987-02-18, Gender: Female, District:         \n",
       "                  Sindhuli, Municipality: Sabhapokhari, Father's Name: Nites Dom, Mother's Name: Hija Lhamu Rawal' \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class EvalConfig:\n",
    "    MODEL_DIR = \"/kaggle/working/ocr_correction_model\"\n",
    "    DATASET_PATH = \"/kaggle/input/ocr-post-correction/combined.csv\" \n",
    "    INPUT_COLUMN = \"input_text\"\n",
    "    TARGET_COLUMN = \"output_text\"\n",
    "    PREFIX = \"correct OCR error: \"\n",
    "    BATCH_SIZE = 16\n",
    "\n",
    "def main_refined_evaluation():\n",
    "    config = EvalConfig()\n",
    "    console = Console()\n",
    "    \n",
    "    with console.status(\"[bold green]Loading model and tokenizer...\") as status:\n",
    "        try:\n",
    "            model = AutoModelForSeq2SeqLM.from_pretrained(config.MODEL_DIR)\n",
    "            tokenizer = AutoTokenizer.from_pretrained(config.MODEL_DIR)\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            model.to(device)\n",
    "            console.log(\"Model loaded successfully.\")\n",
    "        except OSError:\n",
    "            console.print(f\"Error: Model not found at '{config.MODEL_DIR}'. Please run the training cell first.\", style=\"bold red\")\n",
    "            return\n",
    "\n",
    "    with console.status(\"[bold green]Loading and preparing dataset...\") as status:\n",
    "        try:\n",
    "            full_df = pd.read_csv(config.DATASET_PATH, dtype=str).fillna('')\n",
    "            test_df = full_df.sample(frac=0.1, random_state=42)\n",
    "            ocr_texts = test_df[config.INPUT_COLUMN].tolist()\n",
    "            ground_truth_texts = test_df[config.TARGET_COLUMN].tolist()\n",
    "        except FileNotFoundError:\n",
    "            console.print(f\"Error: Dataset not found at '{config.DATASET_PATH}'.\", style=\"bold red\")\n",
    "            return\n",
    "        except KeyError as e:\n",
    "            console.print(f\"Error: Column {e} not found in the dataset.\", style=\"bold red\")\n",
    "            return\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(ocr_texts), config.BATCH_SIZE), desc=\"Predicting\", leave=False):\n",
    "        batch_texts = ocr_texts[i:i + config.BATCH_SIZE]\n",
    "        prefixed_batch = [config.PREFIX + text for text in batch_texts]\n",
    "        \n",
    "        inputs = tokenizer(prefixed_batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(**inputs, max_length=128, num_beams=5, early_stopping=True)\n",
    "        \n",
    "        batch_preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "        predictions.extend(batch_preds)\n",
    "\n",
    "    with console.status(\"[bold green]Calculating evaluation metrics...\") as status:\n",
    "        cer_score = jiwer.cer(ground_truth_texts, predictions)\n",
    "        wer_score = jiwer.wer(ground_truth_texts, predictions)\n",
    "        bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "        bleu_score = bleu_metric.compute(predictions=predictions, references=[[ref] for ref in ground_truth_texts])\n",
    "        exact_matches = sum(1 for pred, ref in zip(predictions, ground_truth_texts) if pred.strip() == ref.strip())\n",
    "        em_score = exact_matches / len(predictions)\n",
    "\n",
    "    table = Table(title=\"Model Evaluation Report\", show_header=True, header_style=\"bold magenta\")\n",
    "    table.add_column(\"Metric\", style=\"dim\", width=25)\n",
    "    table.add_column(\"Score\", justify=\"right\")\n",
    " \n",
    "    table.add_row(\"Character Error Rate (CER)\", f\"{cer_score:.4f}\")\n",
    "    table.add_row(\"Word Error Rate (WER)\", f\"{wer_score:.4f}\")\n",
    "    table.add_row(\"BLEU Score\", f\"{bleu_score['score']:.2f})\")\n",
    "    table.add_row(\"Exact Match (EM %)\", f\"{em_score*100:.2f}%\")\n",
    "    \n",
    "    console.print(table)\n",
    "    \n",
    "    console.print(\"\\ Random Sample Predictions ---\", style=\"bold yellow\")\n",
    "    \n",
    "    random_indices = random.sample(range(len(predictions)), 3)\n",
    "    \n",
    "    for i, index in enumerate(random_indices):\n",
    "        \n",
    "        sample_table = Table(title=f\"Sample {i+1}\", show_header=False, box=None, padding=(0,1))\n",
    "        sample_table.add_column(width=15)\n",
    "        sample_table.add_column()\n",
    "        sample_table.add_row(\"[bold]Input[/bold]\", f\": '{ocr_texts[index]}'\")\n",
    "        sample_table.add_row(\"[bold green]Ground Truth[/bold green]\", f\": '{ground_truth_texts[index]}'\")\n",
    "        sample_table.add_row(\"[bold cyan]Model Output[/bold cyan]\", f\": '{predictions[index]}'\")\n",
    "        console.print(sample_table)\n",
    "        \n",
    "main_refined_evaluation()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7719704,
     "sourceId": 12251816,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
